---
layout: default
title: Service Deployment
parent: Micro Service Architecture Pattern
nav_order: 9
---

# Service Deployment
{: .no_toc }


## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---


## **서비스 배포 개요**
- 서비스 배포는 배포 프로세스와 배포 아키텍처라는 상호 연관된 개념의 조합임
- 배포 프로세스 
  - 소프트웨어를 프로덕션에 반영하기 위해 사람 (개발/운영자)이 해야 하는 단계들로 구성
  - 개발자가 운영 팀에 코드를 일일이 넘겨주던 수작업 과정에서 데브옵스DevOps 체제하에 코드 배포용 콘솔이나 자동화된 배포 파이프라인으로 개발 팀이 직접 자기가 애플리케이션 또는 서비스를 배포하는 방식으로 변경됨
- 배포 아키텍처 
  - 소프트웨어가 실행되는 환경의 구성
  - 웹로직 WebLogig 이나 웹스피어 WebSphere 같은 고가의 애플리케이션 서버를 사용하는 물리적인 프로덕션 환경에서 점점 가볍고 일시적인 컴퓨팅 인프라로 대체됨
  - 수명이 긴 물리 / 가상 머신을 급속히 대체한 자동화한 클라우드에 기반한 가상 머신은 기본적으로 불변이고 immutable, 언제든지 처분 가능하며, 재구성 reconfiguration 하기보다는 폐기 후 재생성한다
- 프로덕션 환경의 4대 필수 기능
  - 서비스 관리 인터페이스 service management interface : 개발자가 서비스를 생성, 수정, 구성할 수 있는 인터페이스를 제공한다. CLI 이나 GUI 배포 툴에서 호출하는 REST API가 가장 좋다
  - 런타임 서비스 관리 runtime service management : 서비스 인스턴스가 항상 적정한 개수만큼 실행되도록 한다. 서비스 인스턴스가 깨지거나 요청을 처리할 수 없을 때, 프로덕션 환경은 해당 인스턴스를 재시동해야 하고, 머신 자체가 깨질 경우 서비스 인스턴스를 다른 머신에서 재시동해야 한다
  - 모니터링 monitoring : 서비스가 무슨 일을 하고 있는지, 로그 파일 및 지표를 개발자가 관찰할 수 있게 한다. 프로덕션 환경은 문제가 있으면 지체 없이 개발자에게 알려야 한다.
  - 요청 라우팅 request routing : 사용자 요청을 서비스로 보낸다


* * *


## **패키징 포맷 배포 패턴**


### **패키징 포맷 배포 개요**
- JAR / WAR 파일 같은 언어에 특정한 패키지 형태로 프로덕션에 배포하는 패턴
- 프로덕션에 배포할 코드와 필요한 런타임을 모두 언어에 특정한 패키지에 넣고 배포하는 방식으로 서비스를 프로덕션에 자동 배포하는 배포 파이프라인을 구축하는 것이 가장 이상적임
- 배포 파이프라인은 실행 가능한 JAR / WAR 파일을 빌드하고, 프로덕션 환경의 서비스 관리 인터페이스를 호출해서 새 버전의 서비스를 배포한다
- 배포된 서비스 인스턴스는 대부분 단일 프로세스이지만, 여러 프로세스로 구성할 때도 있다
  - 자바 서비스 인스턴스는 JDK 또는 JRE가 설치된 머신에서 실행되는 단일 JVM 프로세스이지만, Node.js 서비스는 동시 처리를 위해 여러 개의 워커 프로세스를 파생시킬 수 있다
- 여러 서비스 인스턴스를 같은 머신에 배포
  - 머신 하나에 여러 JVM을 띄워 놓고 JVM당 하나의 서비스 인스턴스를 가동
  - OS 오버헤드는 서비스 인스턴스에 고루 분산
  - 각 서비스 인스턴스는 별도 프로세스로 작동되기 때문에 서로 격리되어 있다
- 여러 서비스 인스턴스를 동일한 웹 컨테이너 또는 애플리케이션 서버에 배포
  - 단일 프로세스에 여러 서비스 인스턴스를 실행
  - OS / 런타임 오버헤드는 모든 서비스 인스턴스에 고루 분산
  - 서비스 인스턴스는 같은 프로세스에 있기 때문에 서로 격리되어 있지 않다 


### **패키징 포맷 배포의 장점**
- 호스트에 서비스를 복사해서 그냥 시동하면 되기 때문에 서비스 인스턴스를 배포하는 속도가 가장 빠르다
- 서비스를 시동하는 시간도 거의 안 걸리고, 오버헤드가 없어서 서비스도 빨리 시동되는 편이다
- 여러 서비스 인스턴스가 머신과 OS를 공유하므로 리소스를 효율적으로 활용할 수 있다

 
### **패키징 포맷 배포의 단점**
- 기술 스택을 캡슐화할 수 없다
  - 운영자는 각 서비스의 배포 방법을 자세히 알고 있어야 한다
  - 서비스별로 런타임 버전이 정해져 있고, 필요한 소프트웨어 패키지 버전이 상이할 수 있으므로 정확하게 구분해서 설치해야 한다
  - 버전이 맞지 않는 이유로 배포 중에 에러가 발생할 가능성이 높다
- 서비스 인스턴스가 소비하는 리소스를 제한할 방법이 없다
- 여러 서비스 인스턴스가 동일 머신에서 실행될 경우 서로 격리할 수 없다
- 서비스 인스턴스를 어디에 둘지 자동으로 결정하기 어렵다
  - 리소스는 한정되어 있고 각 서비스 인스턴스는 일정량의 리소스가 필요하기 때문에 머신을 최대한 효율적으로 활용하는 방향으로 서비스 인스턴스를 배정해야 한다


* * *


## **가상 머신 배포 패턴**


### **가상 머신 배포 개요**
- 서비스를 VM 이미지로 묶어 프로덕션에 배포하는 패턴. 각 서비스 인스턴스가 하나의 VM임
- AWS EC2 서버를 사용하는 경우 서비스를 AMI Amazon Machine Image 로 묶어 배포하고, 서비스 인스턴스인 EC2 인스턴스는 정상 인스턴스를 적당한 개수만큼 작동시키는 AWS 오토 스케일링 그룹으로 관리함
- 배포 파이프라인은 VM 이미지 빌더를 실행해서 서비스 코드 및 소프트웨어 실행에 필요한 각종 라이브러리가 포함된 VM 이미지를 생성하고, VM 이미지 빌더는 리눅스 init 시스템을 이용하여 VM 부팅 시 애플리케이션이 실행되도록 VM 이미지 머신을 구성한다
- VM 이미지 빌드 툴
  - 애미네이터 Aminator : 넷플릭스가 동영상 스트리밍 서비스를 AWS에 배포하는 데 사용했던 툴
  - 패커 Packer : EC2, 디지털 오션 Digital Ocean, 버추얼 박스, VMWare 등 다양한 가상화 기술을 지원
- AWS 일래스틱 빈스토크 Elastic Beanstalk
  - 실행 코드를 WAR 파일로 묶어 업로드하면, 서비스를 부하 분산된 하나 이상의 매니지드 EC2 인스턴스로 배포
  - 애플리케이션을 VM으로 배포하지만 AMI를 빌드하는 것이 아니라 시동 시 애플리케이션을 설치하는 기초 이미지를 사용함


### **가상 머신 배포의 장점**
- VM 이미지로 기술 스택을 캡슐화한다
  - 서비스와 연관된 디펜던시를 모두 VM 이미지에 담을 수 있고, 서비스 실행에 필요한 소프트웨어를 빈틈없이 설치 / 설정할 수 있어 에러날 일이 거의 없다
  - VM 이미지는 따로 수정할 필요 없이 어디라도 배포할 수 있고 VM 관리 API로 간단하고 확실하게 배포할 수 있다
- 서비스 인스턴스가 격리된다
  - 정해진 CPU / 메모리 리소스가 가상 머신마다 배정되므로 다른 서비스에 있는 리소스를 빼앗아 올 수 없다
- 성숙한 클라우드 인프라를 활용한다
  - AWS 등의 퍼블릭 클라우드는 물리 머신에 과부하를 유발하지 않는 방향으로 여러 VM을 스케줄링하며, VM 간 부하 분산 및 자동 확장 등 유용한 부가 기능을 제공한다


### **가상 머신 배포의 단점**
- 리소스를 효율적으로 활용할 수 없다
  - 서비스 인스턴스마다 OS를 포함한 전체 가상 머신의 오버헤드가 있고, 퍼블릭 IaaS 가상 머신은 대부분 VM 크기가 한정되어 있어서 VM을 십분 활용하기 어렵다
  - 특히 가벼운 Node.js 나 고 언어 서비스라면 비효율적이다
- 배포가 비교적 느리다
  - VM 이미지는 대부분 크기가 커서 빌드 시간이 몇 분 정도 걸리고 네트워크를 통해 이동하는 데이터양도 많다
  - VM 인스턴스를 생성할 때에도 다소 시간이 걸리는 편이다
- 시스템 관리 오버헤드가 발생한다
  - OS / 런타임 패치를 해야 하는 시스템 관리가 필요하다


* * *


## **컨테이너 배포 패턴**


### **컨테이너 배포 개요**
- 서비스를 컨테이너 이미지로 묶어 프로덕션에 배포하는 패턴. 각 서비스 인스턴스가 곧 하나의 컨테이너임
- 컨테이너는 OS 수준에서 가상화한 메커니즘으로 다른 컨테이너들과 격리된 샌드박스에서 하나 이상의 프로세스로 실행됨
- 일반적으로 하나의 머신에 여러 컨테이너가 실행되며, 컨테이너는 모두 동일한 OS를 공유하지만 마치 자체 머신에서 실행되는 것처럼 실행되고, 고유한 IP 주소를 갖고 있으며, 자체 루트 파일 시스템을 갖고 있고, 서로 격리되어 있음
- 컨테이너를 생성할 때 CPU, 메모리, I/O 리소스를 지정할 수 있고, 컨테이너 런타임은 컨테이너가 지정된 임계치를 초과하여 머신 리소스를 독차지하지 않도록 감시함
- 쿠버네티스 같은 오케스트레이션 프레임워크는 컨테이너가 요청한 리소스에 따라 컨테이너를 실행할 머신을 선택하고 머신에 과부하가 걸리지 않도록 한다
- 배포 파이프라인은 빌드 타임에 컨테이너 이미지 빌드 툴로 서비스 코드 및 이미지 디스크립션을 읽고 컨테이너 이미지를 생성한 후 레지스트리에 보관하고, 런타임에 레지스트리에서 컨테이너 이미지를 당겨 와 컨테이너를 생성한다

 
### **도커 컨테이너 배포**
- 컨테이너 이미지 
  - 애플리케이션과 서비스 구동에 필요한 모든 소프트웨어로 구성된 파일 시스템 이미지
  - 대부분 온전한 리눅스 루트 파일 시스템 이미지임
  - 스프링 부트 서비스의 경우 실행 가능한 서비스 JAR 파일, 정확한 버전의 JDK가 포함된 컨테이너 이미지를 빌드해서 배포
  - 자바 웹 애플리케이션의 경우 WAR 파일, 아파치 톰캣, JDK가 모두 포함된 컨테이너 이미지를 빌드해서 배포
- 도커 이미지 빌드
  - 도커 컨테이너 이미지를 빌드하는 방법이 기술된 도커파일 Dockerfile 을 생성
  - 도커파일에 기초 컨테이너 이미지를 지정하고 소프트웨어 설치 및 컨테이너 구성에 관한 커맨드를 나열한 후, 컨테이너 생성 시 실행할 셸 커맨드를 기재함
  - 도커파일 생성 후 서비스 JAR 파일을 빌드하고 도커 build 커맨드로 이미지를 생성함
- 도커 이미지 푸시
  - 도커 레지스트리 Docker registry : 자바 라이브러리가 집합된 메이븐 저장소나 Node.js 패키지가 모여있는 npm 레지스트리 같은 것으로 도커 허브 Docker hub 는 대표적인 퍼블릭 도커 레지스트리로 메이븐 센트럴 Maven Central 이나 NpmJS.org 와 비슷한 역할을 함
  - ```tag``` 커맨드로 이미지 앞에 호스트명과 레지스트리 포트(옵션)을 붙이고, 이미지명 뒤에 버전을 붙임
  - ```push``` 커맨드로 태그를 붙인 이미지를 레지스트리에 업로드함
  - 도커 이미지에 있는 계층화 파일 시스템으로 목적지에 존재하지 않는 계층만 전송하므로 전체 이미지의 일부분만 차지하는 애플리케이션 계층은 신속하게 전송됨
- 도커 컨테이너 실행
  - 컨테이너 인프라는 이미지를 레지스트리에서 프로덕션 서버로 당겨 오고, 이 이미지로부터 하나의 서비스 인스턴스인 컨테이너를 하나 이상 만든다
  - ```run``` 커맨드는 컨테이너를 생성 / 시동하는 도커 커맨드로 컨테이너 이미지, 런타임 컨테이너 내부에 세팅할 환경 변수 등 다양한 인수를 받기 때문에 DB 네트워크 위치 등의 외부화 구성 정보를 전달할 수 있다
  - ```run``` 커맨드는 필요 시 레지스트리에서 이미지를 당겨오고, 컨테이너가 생성 / 시동되면 도커파일에 지정된 커맨드가 실행된다
  - ```run``` 커맨드는 단일 머신에서 실행되는 컨테이너를 생성하므로 머신 충돌까지는 처리할 수 없고, DB나 메시지 브로커 등 다른 서비스에 의존하는 경우 서비스와 디펜던시까지 한 단위로 묶어 배포/배포해제 할 수 없다
  - 도커 컴포즈 Docker Compose : 컨테이너를 YAML 파일에 선언적으로 정의할 수 있게 해주는 툴로 여러 컨테이너를 하나의 그룹으로 묶어 시동 / 중지할 수 있고, 다양한 외부화 구성 프로퍼티를 YAML 파일에 간편하게 지정할 수 있다
  - 도커 컴포즈 역시 단일 머신에 국한되는 문제가 있으므로 개발 중에는 유용하지만, 프로덕션에서는 쿠버네티스 처럼 여러 머신을 하나의 리소스 풀로 전환해 주는 도커 오케스트레이션 프레임워크가 필요하다

 
### **컨테이너 배포의 장점**
- 기술 스택의 캡슐화
  - 컨테이너 API로 서비스 관리를 할 수 있다
- 서비스 인스턴스가 격리된다
- 서비스 인스턴스의 리소스를 제한할 수 있다
- 가상 머신보다 가벼운 기술로 컨테이너 이미지 빌드가 빠르고 시동도 매우 빠르다

 
### **컨테이너 배포의 단점**
- 컨테이너 이미지를 직접 관리해야 한다
- OS와 런타임 패치를 정기적으로 해주어야 한다
- 컨테이너 인프라 및 실행 기반인 VM 인프라를 직접 관리해야 한다

 
* * *


## **쿠버네티스 서비스 배포**


### **쿠버네티스 개요**
- 쿠버네티스 Kubernetes 
  - 도커가 실행되는 여러 머신을 하나의 리소스 풀로 취급하는 도커 오케스트레이션 프레임워크
  - 서비스 인스턴스나 머신이 깨지더라도 항상 서비스 인스턴스별 개수가 원하는 만큼 실행되도록 유지함
- 쿠버네티스 주요 기능
  - 리소스 관리 : 여러 머신을 CPU, 메모리, 스토리지 볼륨을 묶어 놓은 하나의 리소스 풀로 취급
  - 스케줄링 : 컨테이너의 리소스 요건 및 노드별 리소스 상황에 따라 컨테이너를 실행할 머신을 선택함. 유사성 affinity을 찾아내 여러 컨테이너를 같은 노드에 배치하거나, 반유사성 anti-affinity 을 발견하여 컨테이너를 다른 노드에 옮김
  - 서비스 관리 : 마이크로서비스에 직접 매핑되는 서비스를 명명하고 버저닝함. 정상 인스턴스를 항상 적정 개수 만큼 가동시키고 요청 부하를 인스턴스에 고루 분산하며, 서비스를 롤링 업데이트하는 기능을 지원함
  - cf. 롤링 업데이트 : 파드 pod 인스턴스를 점진적으로 새로운 것으로 업데이트하여 디플로이먼트 deployment 업데이트가 서비스 중단 없이 이루어질 수 있게 함
- 쿠버네티스 아키텍처
  - 쿠버네티스는 클러스터를 관리하는 소수의(보통 하나의) 마스터 master 와 서비스를 실행하는 하나 이상의 노드 node 들로 구성된 쿠버네티스 클러스터에서 실행된다
  - 마스터는 서비스 배포 / 관리용 REST API인 API 서버와 클러스터 데이터를 저장하는 키-값 NoSQL DB인 etcd, 파드를 실행할 노드를 선택하는 스케줄러, 클러스터가 원하는 상태가 되도록 제어하는 컨트롤러를 실행하는 컨트롤러 관리자 같은 클러스터 관리 컴포넌트를 실행한다
  - 노드는 노드에서 실행되는 파드를 생성 / 관리하는 큐블릿 kubelet, 애플리케이션 요청을 파드로 라우팅하는 네트워킹 관리를 하는 큐브 프록시 kube-proxy, 애플리케이션 컨테이너인 파드를 실행한다.
- 쿠버네티스 핵심 개념
  - 파드 pod : 쿠버네티스의 기본 배포 단위로 IP 주소, 스토리지 볼륨을 공유하는 하나 이상의 컨테이너로 구성됨. 보통 JVM 실행 컨테이너처럼 하나의 컨테이너로 구성하지만 지원 기능이 구현된 사이드카 컨테이너 sidecar container 가 하나 이상 포함된 경우도 있음. 파드의 컨테이너와 파드가 실행하는 노드, 둘 중 하나는 언제라도 깨질 수 있기 때문에 파드는 일시적 ephemeral 임
  - 디플로이먼트 deployment : 파드의 선언형 명세로 파드 인스턴스를 원하는 개수만큼 실행시키는 컨트롤러임. 롤링 업데이트 / 롤백 기능이 탑재된 버저닝을 지원함
  - 서비스 service : 클라이언트에 안정된 정적 네트워크 위치를 제공하며 인프라에서 제공된 서비스 디스커버리 형태를 따름. IP 주소와 DNS 명이 할당된 서비스는 TCP / UDP 트래픽을 하나 이상의 파드에 고루 분산하고 IP 주소와 DNS 명은 쿠버네티스 내부에서만 접근할 수 있음.
  - 컨피그맵 ConfigMap : 하나 이상의 애플리케이션 서비스에 대한 외부화 구성이 정의된 이름-값 쌍의 컬렉션으로 파드 컨테이너의 데피니션은 컨테이너 환경 변수를 정의하기 위해 컨피그맵을 참조함. 컨피그맵을 이용하여 컨테이너 내부에서 구성 파일을 만들 수 있고, 패스워드 처럼 민감한 정보는 시크릿 Secret 이라는 컨피그맵 형태로 저장함

 
### **서비스 배포**
- 디플로이먼트를 YAML 파일로 정의
  - 실행되는 도커 이미지와 환경 변수 값 등은 컨테이너 데피니션에 명시
  - readinessProbe : 트래픽을 해당 서비스 인스턴스로 라우팅해도 괜찮은지 알아보는 헬스 체크. 연속 횟수 (default 1) 만큼 성공하면 서비스가 준비되었다고 간주하고, 특정 횟수 (default 3) 만큼 실패하면 준비가 덜 되었다고 봄
  - livenessProbe : 서비스 인스턴스를 중지 / 재시작해야 할지 판달할 수 있는 근거를 제공. 특정 횟수 (default 3) 만큼 연속 실패하면 해당 서비스를 중단 / 재시동
- ```kubectl create secret``` 으로 쿠버네티스 시크릿을 생성
  - 시크릿을 안전하게 생성하는 방법은 쿠버네티스 문서를 참조
- ```kubectl apply``` 커맨드로 디플로이먼트를 생성 / 수정
- 서비스를 YAML 파일로 정의
  - 서비스는 IP 주소 및 DNS 명이 할당되어 하나 이상의 파드 클라이언트에 안정된 endpoint을 제공하며, 자신의 IP 주소로 향하는 트래픽 부하를 여러 파드에 고루 분산함
  - 셀렉터 selector : app 라벨 값으로 대상 파드를 선택. 디플로이먼트 정의 시 app 라벨을 붙여서 생성된 파드를 대상으로 선택함
- ```kubectl apply``` 커맨드로 서비스를 생성
  - 서비스는 클러스터 내부에서만 접근 가능하므로 클러스터 외부에서 접근 가능하려면 다른 타입의 서비스를 정의해야 한다

 
### **API 게이트웨이 배포**
- NodePort 서비스
  - nodePort : 광역 클러스터 포트 cluster-wide port 를 통해 클러스터의 모든 노드에 접근할 수 있음
  - 광역 클러스터 포트를 경유한 트래픽은 모두 백엔드 파드로 부하 분산 처리됨
  - 광역 클러스터 포트 번호는 30000 ~ 32767 중에 택일해야 함
  - http://<node-ip-address>:nodePort URL로 외부에서 접근 가능함
- NodePort 서비스를 구성한 후 인터넷에서 들어온 요청을 노드에 부하 분산하도록 AWS ELB를 구성
- LoadBalancer 서비스
  - 클라우드에 특정한 부하 분산기를 자동 구성하는 서비스

 
### **무중단 배포**
- 무중단 배포 절차
  - 이미지에 붙인 버전 태그만 달리하여 새 컨테이너 이미지를 빌드하고 레지스트리에 푸시
  - 새 이미지를 참조하도록 YAML 파일의 서비스 디플로이먼트 부분을 편집
  - ```kubectl apply -f``` 커맨드로 디플로이먼트를 업데이트
- 롤링 업데이트 
  - 쿠버네티스는 단계적으로 새 버전을 실행하는 파드를 생성하고 구 버전을 실행하는 파드를 중지함
  - readinessProbe로 헬스 체크를 해서 파드마다 신 버전이 요청 처리 준비가 완료되기 전에는 구 버전을 중지하지 않음
- 새 버전의 파드 시동이 실패하는 경우
  - YAML 파일을 정정 후 ```kubectl apply -f``` 를 재실행해서 디플로이먼트를 업데이트
  - ```kubectl rollout undo deployment``` 커맨드로 디플로이먼트를 롤백
  - cf. 롤아웃 rollout : 디플로이먼트가 관리하는 이력으로 업데이트 할 때마다 생성됨

 
### **배포와 릴리스 분리**
- 서비스 배포와 릴리스 
  - 서비스 배포 : 서비스를 프로덕션에서 실행하여 작동시키는 것
  - 서비스 릴리스 : 최종 사용자에게 서비스를 제공하여 운영 트래픽을 처리할 수 있게 만드는 것
- 운영환경과 스테이징 환경의 차이
  - 운영 환경은 스테이징 환경보다 훨씬 더 용량이 큰 트래픽을 처리
  - 두 환경을 정확히 동기화하는 것은 시간이 너무 많이 소요됨
  - 정확히 동일한 레플리카로 맞추었다 하더라도 테스트가 모든 버그를 잡아낸다는 보장이 없음
- 분리 배포 절차
  - 최종 사용자 요청을 서비스에 라우팅하지 않고 새 버전의 서비스를 프로덕션에 배포
  - 프로덕션에서 새 버전을 테스트
  - 소수의 최종 사용자에게 새 버전을 릴리스
  - 점점 더 많은 사용자에게 새 버전을 릴리스
  - 문제가 생기면 곧바로 구 버전으로 롤백. 새 버전이 정확하게 잘 동작하면 구 버전을 삭제
- 서비스 메시는 규칙 기반의 부하 분산 및 트래픽 라우팅 기능을 제공하므로 여러 버전의 서비스를 동시에 확실하게 실행할 수 있음

 
### **이스티오 서비스 메시**
- 이스티오 Istio : 구글, IBM, 리프트 Lyft 가 공동 개발한 마이크로서비스를 연결, 관리, 보안하는 오픈 플랫폼으로 모든 서비스 네트워크 트래픽이 통과하는 네트워킹 계층
- 이스티오의 기능
  - 트래픽 관리 : 서비스 디스커버리, 부하 분산, 라우팅 규칙, 회로 차단기
  - 보안 : 전송 계층 보안 TLS 을 이용한 서비스 간 통신 보안
  - 텔레메트리 telemetry : 네트워크 트래픽 관련 지표 수집 및 분산 추적
  - 정책 집행 : 쿼터 및 사용률 제한 정책 적용
- 이스티오 아키텍처
  - 컨트롤 플레인 control plane : 데이터 플레인이 트래픽을 라우팅하도록 구성하는 등의 관리 역할. 하부 인프라에서 배포된 서비스 관련 정보를 추출하고 엔보이 프록시가 미리 정의된 규칙에 따라 트래픽을 라우팅하도록 구성하는 파일럿 pilot 과 엔보이 프록시에서 텔레메트리를 수집하고 정책을 집행하는 믹서 mixer로 구성
  - 데이터 플레인 data plane : 서비스를 드나드는 트래픽을 라우팅하는 엔보이 프록시 envoy proxy로 구성. 엔보이 프록시는 엔보이 Envoy를 변형한 것으로 다양한 프로토콜을 지원하는 고성능 프록시로 회로 차단기, 사용량 제한, 자동 재시도 등 서비스 간 통신을 확실하게 지원하고 애플리케이션 내부에서 TLS로 엔보이 간 통신을 보안함
  - 서비스의 트래픽은 엔보이 프록시를 통해 흘러가며 컨트롤 플레인에 명시된 규칙에 따라 트래픽이 라우팅됨
- 사이드카 패턴
  - 횡단 관심사는 서비스 인스턴스와 함께 실행되는 사이드카 프로세스나 컨테이너에 구현하는 패턴
  - 이스티오는 엔보이를 사이드카로 활용
  - 쿠버네티스에서는 서비스 파드 내부의 컨테이너 중 하나로 엔보이 프록시를 실행하고 파드 개념이 없는 환경에서는 동일한 컨테이너에서 하나의 서비스로 엔보이를 실행
- 서비스 배포
  - 배포하려는 애플리케이션 서비스마다 쿠버네티스 서비스와 디플로이먼트를 정의
  - 쿠버네티스 서비스 포트는 <프로토콜>[접미어] 포맷으로 작성. 익명 포트는 TCP 포트로 간주해서 규칙 기반의 라우팅을 적용하지 않음
  - 분산 추적을 하려면 파드에 ```app``` 라벨을 붙여 서비스를 식별
  - 여러 버전의 서비스를 동시에 실행하려면 쿠버네티스 디플로이먼트 명에 버전을 넣어야 함. 디플로이먼트의 파드에는 버전 식별 라벨을 붙여야 이스티오가 해당 버전으로 라우팅함
  - ```istioctl kube-inject … | kubectl apply``` 커맨드로 쿠버네티스 YAML 파일을 읽어 엔보이 프록시가 포함된 수정된 구성을 출력하거나 자동 사이드카 주입 automatic sidecar injection을 활용
- 라우팅 규칙 생성
  - 이스티오가 전체 트래픽을 현재 버전으로 라우팅하도록 규칙을 생성
  - VirtualService : 하나 이상의 호스트명에 대한 요청을 어떻게 라우팅할지 라우팅 규칙을 정의하는 이스티오 객체. 트래픽을 하위 집합으로 보내도록 라우팅한다
  - DestinationRule : 하나 이상의 서비스 파드에 대한 하위 집합 subset 이 정의된 이스티오 객체. 파드의 하위 집합은 대부분 서비스 버전이며, DestinationRule 에는 부하 분산 알고리즘 등 트래픽 정책도 정의할 수 있다
- 새 버전 배포
  - 디플로이먼트 명에 버전을 넣고, ```version``` 라벨을 파드에 붙여 새 버전 서비스 배포
  - 디플로이먼트를 생성하면 두 버전이 함께 실행되지만 라우팅 규칙에 따라 새 버전에는 트래픽을 보내지 않는다
- 새 버전 테스트
  - 테스트 사용자를 식별할 수 있는 헤더를 붙인 요청은 새 버전으로 향하도록 VirtualService를 수정
  - ```match : header:``` 로 라우팅 규칙을 추가
- 새 버전 라우팅
  - 운영 트래픽의 일부를 새 버전으로 향하도록 VirtualService를 수정
  - ```weight :``` 로 트래픽 비중을 정의하는 라우팅 규칙을 추가
  - 트래픽 양을 점점 늘리다가 새 버전이 100 % 처리하게 되면 신구 버전을 잠시 공존하게 놔둔 후 구 버전은 삭제

 
* * *


## **서버리스 배포 패턴**


### **서버리스 배포 개요**
- 퍼블릭 클라우드에서 제공하는 서버리스 배포 메커니즘을 이용하여 서비스를 배포하는 패턴
- 컴퓨팅 리소스를 사전에 프로비저닝해야할 필요가 없고, 사람이 직접 시스템 관리를 해야할 필요가 없음
- 서버리스 배포 기술
  - AWS의 AWS 람다, 구글 클라우드의 구글 클라우드 함수 Google Cloud functions, 마이크로소프트 애저의 애저 함수 Azure functions 등
  - 아파치 오픈위스크 Apache Openshisk, 쿠버네티스를 위한 피션 Fission 등의 오픈 소스 서버리스 프레임워크도 있지만, 서버리스 프레임워크는 그것을 실행하는 인프라를 관리해야 하는 단점이 있음
- AWS 람다
  - 자바, Node.js, C#, 고 언어, 파이썬을 지원
  - AWS 서비스를 호출하여 요청을 처리하는 무상태 stateless 서비스
  - 애플리케이션을 ZIP 또는 JAR 파일로 묶어 AWS 람다에 업로드하고 함수명을 지정하면 들어온 요청을 처리하기에 충분한 개수만큼 마이크로서비스 인스턴스를 자동 실행함
  - 요청별 소요 시간 및 메모리 사용량에 해당하는 비용만 지불하면 되므로 서버, 가상 머신, 컨테이너 관련 부분을 신경 쓸 필요가 없다는 점에서 매우 강력함

 
### **람다 함수 개발**
- 프로그래밍 언어마다 코드 및 패키징이 다름
- 자바 람다 함수
  - AWS 람다의 자바 코어 라이브러리에 포함된 제네릭 인터페이스 RequestHandler 를 구현
  - 람다 함수가 처리할 요청에 따라 입력 타입인 I, 출력 타입인 O, 두 타입의 매개 변수를 받음
  - ```handleRequest()``` 메서드 : 입력 객체와 컨텍스트를 매개 변수로 받고 출력 객체를 반환. AWS API 게이트웨이에서 프록싱되어 들어오는 HTTP 요청을 처리하는 경우 I는 ```APIGatewayProxyRequestEvent```, O는 ```APIGatewayProxyResponseEvent``` 임
  - ZIP 또는 JAR 파일로 패키징. JAR 파일은 메이븐 셰이드 Maven Shade 플러그인으로 생성한 우버 uber JAR 파일이고, ZIP 파일은 내부에 루트 디렉터리에 클래스가 있고 lib 디렉터리에 JAR 디펜던시가 있음

 
### **람다 함수 호출**
- HTTP 요청 처리
  - AWS API 게이트웨이가 HTTP 요청을 람다 함수로 라우팅
  - API 게이트웨이는 람다 함수를 HTTPS endpoint 로 표출하고, HTTP 요청 객체가 들어오면 람다 함수로 전달하여 HTTP 응답 객체를 반환하는 HTTP 프록시 역할을 함
  - API 게이트웨이와 AWS 람다를 함께 사용하면 REST 서비스를 람다 함수로 배포하는 것도 가능함
- AWS 서비스에서 생성된 이벤트 처리
  - S3 버킷에 객체가 생성되는 이벤트
  - DynamoDB 테이블의 데이터 항목이 생성, 수정, 삭제되는 이벤트
  - 키네시스 스트림에서 메시지를 읽을 준비가 되는 이벤트
  - SES를 통해 이메일을 수신하는 이벤트
  - 다른 AWS 서비스와 완벽하게 연계되므로 유용함
- 스케줄링 처리
  - 리눅스 크론 같은 스케줄러로 람다 함수가 주기적으로 호출되도록 설정
  - 크론 표현식으로 구체적이고 유연하게 스케줄을 지정할 수 있음
- API 호출 처리
  - 애플리케이션이 웹 서비스를 요청해서 람다 함수를 호출
  - 람다 함수 명과 입력 이벤트 데이터를 지정하고, 람다 함수를 동기 / 비동기 호출
  - 동기 호출 시 웹 서비스의 HTTP 응답에는 람다 함수의 응답 본문이 반환되고, 비동기 호출 시 람다 실행이 성공적으로 시작되었음을 알리는 응답이 반환됨

 
### **람다 함수의 장점**
- 다양한 AWS 서비스와의 연계
  - DynamoDB, 키네시스 등 AWS 서비스의 이벤트를 소비할 수 있음
  - AWS API 게이트웨이를 통해 HTTP 요청을 처리하는 람다를 쉽게 작성할 수 있음
- 시스템 관리 업무가 경감됨
  - 저수준의 시스템 관리를 신경 쓸 필요가 없음
  - OS, 런타임 패치를 신경 쓸 필요 없음
- 탄력성
  - 애플리케이션 부하 처리에 필요한 개수만큼 인스턴스를 실행하므로 필요한 능력을 예측할 필요가 없음
  - VM / 컨테이너를 과대 / 과소 프로비저닝할 위험이 없음
- 사용량 과금
  - VM / 컨테이너가 유휴 상태인 동안에도 과금되는 일반적인 IaaS 클라우드와 달리 실제로 요청을 처리하기 위해 소비한 리소스만큼 비용을 지불
 

### **람다 함수의 단점**
- 긴-꼬리 지연 long-tail latency
  - 코드를 동적 실행하므로 AWS가 애플리케이션 인스턴스를 프로비저닝하고 애플리케이션을 시동하기까지 시간이 걸림
  - 특히 자바로 작성한 서비스는 보통 시동 시간이 적어도 수 초는 걸리므로 지연 시간이 매우 중요한 서비스라면 적합하지 않을 수 있음
- 제한된 이벤트 / 요청 기반 프로그래밍 모델
  - 서드파티 메시지 브로커에 유입된 메시지를 소비하는 서비스 같은 실행 시간이 긴 서비스를 배포할 용도가 아님

 
* * *


## **람다 서비스 배포**


### **AWS 람다 서비스 설계**
- 스프링 MVC 컨트롤러 대신 AWS 람다 요청 핸들러 클래스를 사용하는 것만 다를 뿐 비즈니스 로직은 그대로임
- 표현 계층에는 람다 함수를 구현한 요청 핸들러 클래스가 있고, 비즈니스 계층에는 서비스 클래스, 엔터티, 리포지터리로 구성된다
- AbstractHttpHandler 클래스
  - AWS SDK의 ```RequestHandler<APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent>``` 인터페이스를 구현 
  - 요청 처리 시 발생한 예외를 붙잡아 에러 코드 500을 던짐
- AbstractAutowiringHttpReqeustHandler 클래스
  - AbstractHttpHandler 클래스를 상속하여 요청 핸들러에 필요한 디펜던시를 주입하는 클래스
  - ```SpringApplication.run()``` 으로 ApplicationContext를 생성 후 최초로 들어온 요청을 처리하기 전에 ```beforeHandling()```으로 디펜던시를 자동와이어링 autowire 함
- ServiceRequestHandler 클래스 
  - AbstractAutowiringHttpReqeustHandler 클래스를 상속하여 실질적으로 요청을 처리하는 클래스
  - ```handleHttpRequest()``` 메서드는 HTTP 요청을 나타낸 ```APIGatewayProxyRequestEvent```를 매개변수로 받고 HTTP 응답에 해당하는 ```APIGatewayProxyResponseEvent```를 반환함

 
### **서비스 패키징**
- 그레이들 태스크를 이용하여 ```buildZip``` 커맨드로 ZIP 파일로 빌드
- 루트 디렉터리에는 클래스/리소스, lib 디렉터리에는 JAR 파일이 있는 ZIP 파일 생성

 
### **람다 함수 배포**
- 오픈 소스 서버리스 프로젝트 OpenSource Serverless Framework 로 람다 함수와 REST endpoint 가 기술된 serverless.yml 파일 작성
- 서버리스 프레임워크가 serverless.yml 파일을 기반으로 람다 함수를 배포하고 이 함수들로 요청을 라우팅하는 API 게이트웨이를 생성 / 구성
- ```provider :``` 로 배포 플랫폼을 설정하고 ```environment :``` 로 환경 변수를 설정해 외부화 구성을 제공함
- ```package :``` 로 람다 함수가 포함된 ZIP 파일을 지정하고 ```function :``` 으로 핸들러 함수, HTTP endpoint로 구성된 람다 함수를 정의함
- 코드를 변경할 경우 ZIP 파일을 다시 빌드해서 람다를 업데이트하고 서버리스 배포
